{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# COVID-19 Vaccines Sentiment Analysis\n------------------","metadata":{}},{"cell_type":"markdown","source":"For this notebook, we will be doing a sentiment analysis for COVID-19 vaccines using data from COVID-19 All Vaccines Tweets, collected using tweepy Python package to access Twitter API. For each of the vaccine I use relevant search term (most frequently used in Twitter to refer to the respective vaccine).\n\nBefore we start, we will be importing the necessary libraries for our analysis. ","metadata":{}},{"cell_type":"code","source":"pip install twython","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \n\nimport matplotlib.pyplot as plt \nimport re\nimport string\n\nimport nltk\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import words\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import PorterStemmer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\nnltk.download('stopwords')\nnltk.download('vader_lexicon')\n\n\nfrom collections import Counter\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib import ticker\nimport seaborn as sns\nimport plotly.express as px\n\nsns.set(style=\"darkgrid\")","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:01:16.681654Z","iopub.execute_input":"2021-10-24T11:01:16.682184Z","iopub.status.idle":"2021-10-24T11:01:20.797561Z","shell.execute_reply.started":"2021-10-24T11:01:16.682106Z","shell.execute_reply":"2021-10-24T11:01:20.796847Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Importing the Dataset","metadata":{}},{"cell_type":"markdown","source":"Now we will be importing the dataset from the COVID-19 All Vaccines Tweets. ","metadata":{}},{"cell_type":"code","source":"path = '../input/all-covid19-vaccines-tweets/vaccination_all_tweets.csv'\ndf = pd.read_csv(path)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:01:54.958365Z","iopub.execute_input":"2021-10-24T11:01:54.958652Z","iopub.status.idle":"2021-10-24T11:01:57.369376Z","shell.execute_reply.started":"2021-10-24T11:01:54.958624Z","shell.execute_reply":"2021-10-24T11:01:57.368675Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Now that we have imported the dataset, we will check the shape of our dataset, to view the number of rows and column.","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:02:30.440657Z","iopub.execute_input":"2021-10-24T11:02:30.441392Z","iopub.status.idle":"2021-10-24T11:02:30.447362Z","shell.execute_reply.started":"2021-10-24T11:02:30.441348Z","shell.execute_reply":"2021-10-24T11:02:30.446431Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"We can see that our dataset have 189,054 rows and 16 columns. But since we would not need all the columns, we will now select the important ones for our analysis, and create a new dataframe. ","metadata":{}},{"cell_type":"code","source":"data = ['user_name', 'date', 'text']\ndf = df[data]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:03:45.925588Z","iopub.execute_input":"2021-10-24T11:03:45.926152Z","iopub.status.idle":"2021-10-24T11:03:45.949546Z","shell.execute_reply.started":"2021-10-24T11:03:45.926114Z","shell.execute_reply":"2021-10-24T11:03:45.948795Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Now that we have a new dataset with the important data for our analysis, we need to check the data types of the dataframe. ","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:05:24.034185Z","iopub.execute_input":"2021-10-24T11:05:24.034864Z","iopub.status.idle":"2021-10-24T11:05:24.115482Z","shell.execute_reply.started":"2021-10-24T11:05:24.034831Z","shell.execute_reply":"2021-10-24T11:05:24.114822Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"We can see that all three of our columns have the same data types. But for the date column, we can see that it is specific to the second of the tweet. Since we wouldn't need such an accurate data for our analysis, we will only take the day, month, and year of the tweet. ","metadata":{}},{"cell_type":"code","source":"df.user_name = df.user_name.astype('category')\ndf.user_name = df.user_name.cat.codes\n\ndf.date = pd.to_datetime(df.date).dt.date\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:05:36.536163Z","iopub.execute_input":"2021-10-24T11:05:36.536417Z","iopub.status.idle":"2021-10-24T11:05:36.896365Z","shell.execute_reply.started":"2021-10-24T11:05:36.536390Z","shell.execute_reply":"2021-10-24T11:05:36.895688Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Now that we have finished importing our dataset, we can continue to process our data for analysis. ","metadata":{}},{"cell_type":"markdown","source":"## Processing the Data","metadata":{}},{"cell_type":"markdown","source":"For processing our data, we will need to select the text column of our dataset. ","metadata":{}},{"cell_type":"code","source":"texts = df['text']\ntexts.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:05:44.703366Z","iopub.execute_input":"2021-10-24T11:05:44.703641Z","iopub.status.idle":"2021-10-24T11:05:44.712111Z","shell.execute_reply.started":"2021-10-24T11:05:44.703605Z","shell.execute_reply":"2021-10-24T11:05:44.711362Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"The first step of our processing would be removing the url from all the tweets, since we don't need them. after that, we will be converting all of the text into lower cases for easier analysis. Lastly, we will also remove all punctuations from the texts. ","metadata":{}},{"cell_type":"code","source":"remove_url = lambda x: re.sub(r'https\\S+', '', str(x))\ntexts_lr = texts.apply(remove_url)\ntexts_lr.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:09:18.658881Z","iopub.execute_input":"2021-10-24T11:09:18.659159Z","iopub.status.idle":"2021-10-24T11:09:19.128346Z","shell.execute_reply.started":"2021-10-24T11:09:18.659131Z","shell.execute_reply":"2021-10-24T11:09:19.127668Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"to_lower = lambda x : x.lower()\ntexts_lc = texts_lr.apply(to_lower)\ntexts_lc.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-10-24T11:09:36.356244Z","iopub.execute_input":"2021-10-24T11:09:36.356502Z","iopub.status.idle":"2021-10-24T11:09:36.541178Z","shell.execute_reply.started":"2021-10-24T11:09:36.356475Z","shell.execute_reply":"2021-10-24T11:09:36.540489Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"rmv_pcs = lambda x : x.translate(str.maketrans('', '', string.punctuation))\ntexts_pcs = texts_lc.apply(rmv_pcs)\ntexts_pcs","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:09:50.001060Z","iopub.execute_input":"2021-10-24T11:09:50.001319Z","iopub.status.idle":"2021-10-24T11:09:51.996449Z","shell.execute_reply.started":"2021-10-24T11:09:50.001291Z","shell.execute_reply":"2021-10-24T11:09:51.995813Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Now that we have remove all the unnecessary characters from our text, we will now remove the stopwords from the text. A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query. This will reduce the noise in our analysis. ","metadata":{}},{"cell_type":"code","source":"update_words = ['covid','#coronavirus', '#coronavirusoutbreak', '#coronavirusPandemic', '#covid19', '#covid_19', '#epitwitter', '#ihavecorona', 'amp', 'coronavirus', 'covid19']\nstop_words = set(stopwords.words('english'))\nstop_words.update(update_words)\n\nremove_words = lambda x : ' '.join([word for word in x.split() if word not in stop_words])\ntexts_rs = texts_pcs.apply(remove_words)\ntexts_rs.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:09:56.673695Z","iopub.execute_input":"2021-10-24T11:09:56.674626Z","iopub.status.idle":"2021-10-24T11:09:57.478893Z","shell.execute_reply.started":"2021-10-24T11:09:56.674577Z","shell.execute_reply":"2021-10-24T11:09:57.478058Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Text Analysis","metadata":{}},{"cell_type":"markdown","source":"Before we analyze the sentiments of the tweets, we will be doing an analysis on the text itself. First, we will be listing all of the words on each of the tweets, and also visualizing it. The purpose is to see the most common words from all of the tweets. ","metadata":{}},{"cell_type":"code","source":"word_list = [word for line in texts_rs for word in line.split()]\nword_list[:10]","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:10:33.820711Z","iopub.execute_input":"2021-10-24T11:10:33.821312Z","iopub.status.idle":"2021-10-24T11:10:34.172313Z","shell.execute_reply.started":"2021-10-24T11:10:33.821275Z","shell.execute_reply":"2021-10-24T11:10:34.171594Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"word_counts = Counter(word_list).most_common(50)\nwords_df = pd.DataFrame(word_counts)\nwords_df.columns = ['word', 'frequency']\n\npx.bar(words_df, x='word', y='frequency', title='Most Common Words')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:11:28.260584Z","iopub.execute_input":"2021-10-24T11:11:28.260849Z","iopub.status.idle":"2021-10-24T11:11:28.655840Z","shell.execute_reply.started":"2021-10-24T11:11:28.260820Z","shell.execute_reply":"2021-10-24T11:11:28.655172Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Join Table","metadata":{}},{"cell_type":"markdown","source":"Since we are done with the processing of the text data, we can now put the cleaned text into our main dataframe.","metadata":{}},{"cell_type":"code","source":"df.text = texts_rs\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:11:40.527394Z","iopub.execute_input":"2021-10-24T11:11:40.527664Z","iopub.status.idle":"2021-10-24T11:11:40.550705Z","shell.execute_reply.started":"2021-10-24T11:11:40.527628Z","shell.execute_reply":"2021-10-24T11:11:40.549640Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:11:49.221261Z","iopub.execute_input":"2021-10-24T11:11:49.222117Z","iopub.status.idle":"2021-10-24T11:11:49.331703Z","shell.execute_reply.started":"2021-10-24T11:11:49.222078Z","shell.execute_reply":"2021-10-24T11:11:49.325110Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Now we see that the date here is still in string type. For our analysis, we need to convert it into datetime data type. Also, to limit  our analysis, we will only be taking tweets from march 1st, 2021. ","metadata":{}},{"cell_type":"code","source":"df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n\nfiltered_df = df.loc[(df['date'] >= '2021-03-01')]\nfiltered_df","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:11:59.734290Z","iopub.execute_input":"2021-10-24T11:11:59.734545Z","iopub.status.idle":"2021-10-24T11:11:59.820545Z","shell.execute_reply.started":"2021-10-24T11:11:59.734518Z","shell.execute_reply":"2021-10-24T11:11:59.819876Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Sentiment Analysis ","metadata":{}},{"cell_type":"markdown","source":"Now that we have finished preparing the data for our analysis, we can continue to with our sentiment analysis. Sentiment Analysis can be organized into neutral, positive, or negative sentiment. To find out, we will be using SentimentIntensityAnalyzer, which will rate whether the tweet containt positive, negative, or neutral sentiment. ","metadata":{}},{"cell_type":"code","source":"sid = SentimentIntensityAnalyzer()\nps = lambda x : sid.polarity_scores(x)\nsentiment_scores = filtered_df.text.apply(ps)\nsentiment_scores","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:12:13.323587Z","iopub.execute_input":"2021-10-24T11:12:13.323862Z","iopub.status.idle":"2021-10-24T11:12:45.404406Z","shell.execute_reply.started":"2021-10-24T11:12:13.323831Z","shell.execute_reply":"2021-10-24T11:12:45.403674Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"sentiment_df = pd.DataFrame(data = list(sentiment_scores))\nsentiment_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:13:10.664082Z","iopub.execute_input":"2021-10-24T11:13:10.664367Z","iopub.status.idle":"2021-10-24T11:13:10.952832Z","shell.execute_reply.started":"2021-10-24T11:13:10.664339Z","shell.execute_reply":"2021-10-24T11:13:10.951884Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"We can see that there is neg for negative sentiment, neu for neutral sentiment, pos for positive sentiment, and compound as the average rate of the sentiment. We will focused on the compound. \n\nFor negative sentiment, the compound score will be closer to -1, and the opposite goes for the positive sentiment, which will be closer to 1. Neutral sentiment will be a 0. \n\nFor our analysis, we will create another column called label, where we will be labelling the scores based on the compound polarity value. ","metadata":{}},{"cell_type":"code","source":"labelize = lambda x : 'neutral' if x==0 else('positive' if x>0 else 'negative')\nsentiment_df['label'] = sentiment_df.compound.apply(labelize)\nsentiment_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:13:33.856898Z","iopub.execute_input":"2021-10-24T11:13:33.857427Z","iopub.status.idle":"2021-10-24T11:13:33.940161Z","shell.execute_reply.started":"2021-10-24T11:13:33.857391Z","shell.execute_reply":"2021-10-24T11:13:33.939491Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Now that we have the label for each tweet, we will join the label column into our main dataframe. Once we have joined the two tables, we will be counting the number of positive, negative, and neutral tweets from our dataframe and visualize it. ","metadata":{}},{"cell_type":"code","source":"data = filtered_df.join(sentiment_df.label)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:13:40.251843Z","iopub.execute_input":"2021-10-24T11:13:40.252539Z","iopub.status.idle":"2021-10-24T11:13:40.293931Z","shell.execute_reply.started":"2021-10-24T11:13:40.252505Z","shell.execute_reply":"2021-10-24T11:13:40.293273Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"counts_df = data.label.value_counts().reset_index()\ncounts_df","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:13:45.027265Z","iopub.execute_input":"2021-10-24T11:13:45.027530Z","iopub.status.idle":"2021-10-24T11:13:45.076474Z","shell.execute_reply.started":"2021-10-24T11:13:45.027502Z","shell.execute_reply":"2021-10-24T11:13:45.075685Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"sns.barplot(data=counts_df, x='index', y='label')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:13:52.321681Z","iopub.execute_input":"2021-10-24T11:13:52.322488Z","iopub.status.idle":"2021-10-24T11:13:52.536274Z","shell.execute_reply.started":"2021-10-24T11:13:52.322453Z","shell.execute_reply":"2021-10-24T11:13:52.535637Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"We can see that mostly, the tweets about the vaccines is neutral, and with more positive than negative. But the visualization that we see is from the total tweets from march to september 2021. \n\nFor closer analyzation, we will see the number of positive, negative, and neutral tweets dialy from march 2021. ","metadata":{}},{"cell_type":"code","source":"data_agg = data[['user_name', 'date', 'label']].groupby(['date', 'label']).count().reset_index()\ndata_agg.columns = ['date', 'label', 'counts']\ndata_agg.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:13:57.448492Z","iopub.execute_input":"2021-10-24T11:13:57.448747Z","iopub.status.idle":"2021-10-24T11:13:57.518148Z","shell.execute_reply.started":"2021-10-24T11:13:57.448720Z","shell.execute_reply":"2021-10-24T11:13:57.517344Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"px.line(data_agg, x='date', y='counts', color='label', title='COVID-19 Vaccines Sentiment Analysis')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T11:14:09.656613Z","iopub.execute_input":"2021-10-24T11:14:09.657343Z","iopub.status.idle":"2021-10-24T11:14:09.762602Z","shell.execute_reply.started":"2021-10-24T11:14:09.657308Z","shell.execute_reply":"2021-10-24T11:14:09.761948Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"From the visualization, we can see that the sentiment of the tweets about COVID-19 Vaccines is mostly neutral. Although there are negative tweets about the vaccines, the positive tweets about the vaccines outweight the negative tweets. ","metadata":{}}]}